{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Spark setup\n",
    "import os\n",
    "import glob\n",
    "import hdf5_getters\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Exploring Million Song Dataset\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Artist: Casual, Song: I Didn't Mean To\n"
     ]
    }
   ],
   "source": [
    "# Inspect some sample data\n",
    "h5 = hdf5_getters.open_h5_file_read('MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5')\n",
    "\n",
    "# in byte format --> decode to string\n",
    "print('Sample Artist: %s, Song: %s' % \\\n",
    "      (hdf5_getters.get_artist_name(h5).decode('UTF-8'), hdf5_getters.get_title(h5).decode('UTF-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 dirs in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MillionSongSubset/A/R/R',\n",
       " 'MillionSongSubset/A/R/U',\n",
       " 'MillionSongSubset/A/R/I',\n",
       " 'MillionSongSubset/A/R/N',\n",
       " 'MillionSongSubset/A/R/G']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all subdirs\n",
    "def get_subdirs(basedir):\n",
    "    subdirs = []\n",
    "    for subdir in next(os.walk(basedir))[1]:\n",
    "        subdirs.append(os.path.join(basedir, subdir))\n",
    "    return subdirs\n",
    "\n",
    "basedir = 'MillionSongSubset'\n",
    "subdirs_rdd = sc.parallelize(get_subdirs(basedir))\n",
    "subsubdirs_rdd = subdirs_rdd.map(lambda subdir: get_subdirs(subdir)).flatMap(lambda x: x)\n",
    "subsubsubdirs_rdd = subsubdirs_rdd.map(lambda subsubdir: get_subdirs(subsubdir)).flatMap(lambda x: x)\n",
    "print('%d dirs in dataset' % (subsubsubdirs_rdd.count()))\n",
    "subsubsubdirs_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 files in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MillionSongSubset/A/R/R/TRARRZU128F4253CA2.h5',\n",
       " 'MillionSongSubset/A/R/R/TRARRJL128F92DED0E.h5',\n",
       " 'MillionSongSubset/A/R/R/TRARRUZ128F9307C57.h5',\n",
       " 'MillionSongSubset/A/R/R/TRARRWA128F42A0195.h5',\n",
       " 'MillionSongSubset/A/R/R/TRARRPG12903CD1DE9.h5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate & get all files (songs)\n",
    "def count_and_get_files(basedir, ext='.h5'):\n",
    "    # modified version of: https://labrosa.ee.columbia.edu/millionsong/pages/iterate-over-all-songs\n",
    "    cnt = 0\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "        cnt += len(files)\n",
    "    return cnt, all_files\n",
    "\n",
    "file_names_rdd = subsubsubdirs_rdd.map(lambda subsubsubdir: count_and_get_files(subsubsubdir)[1]).flatMap(lambda x: x)\n",
    "print('%d files in dataset' % (file_names_rdd.count()))\n",
    "file_names_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RaphaÃ«l',\n",
       " 'Julie Zenatti',\n",
       " 'The Baltimore Consort',\n",
       " 'I Hate Sally',\n",
       " 'Orlando Pops Orchestra']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get artist name for each song\n",
    "def get_artist_name(filename):\n",
    "    h5 = hdf5_getters.open_h5_file_read(filename)\n",
    "    return hdf5_getters.get_artist_name(h5).decode('UTF-8')\n",
    "\n",
    "artist_names_rdd = file_names_rdd.map(get_artist_name)\n",
    "artist_names_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all artists and songs in format: (artist, song)\n",
    "def get_artist_and_song(filename):\n",
    "    h5 = hdf5_getters.open_h5_file_read(filename)\n",
    "    artist = hdf5_getters.get_artist_name(h5).decode('UTF-8')\n",
    "    song = hdf5_getters.get_title(h5).decode('UTF-8')\n",
    "    return artist, song\n",
    "\n",
    "artist_song_rdd = file_names_rdd.map(lambda x: get_artist_and_song(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4412 unique artists in dataset\n",
      "\n",
      "Linkin Park has 3 songs:\n",
      "- Crawling (Album Version)\n",
      "- Given Up (Album Version)\n",
      "- Pushing Me Away (Album Version)\n",
      "\n",
      "Yank Rachell has 2 songs:\n",
      "- My Mind Got Bad\n",
      "- It Seems Like A Dream\n",
      "\n",
      "Neil Diamond has 5 songs:\n",
      "- Hey Louise\n",
      "- Song Sung Blue\n",
      "- Brooklyn On A Saturday Night\n",
      "- Reminisce For A While (Sung With Raul Malo)\n",
      "- Song Sung Blue\n",
      "\n",
      "Pyrolator has 2 songs:\n",
      "- Gold Und Silber\n",
      "- Passage To Melilla\n",
      "\n",
      "Audio Adrenaline has 4 songs:\n",
      "- Some Kind Of Zombie (Criscoteque Remix)\n",
      "- My God  (Audio Adrenaline Album Version)\n",
      "- Will Not Fade  (Hit Parade Album Version (new Song))\n",
      "- Gloria (In The Name Of Love Album Version)\n"
     ]
    }
   ],
   "source": [
    "# group songs by their artist in format: (artist, [song1, song2, song3...])\n",
    "grouped_artist_song_rdd = artist_song_rdd.groupByKey().mapValues(list)\n",
    "n_unique_artists = grouped_artist_song_rdd.count()\n",
    "print('%d unique artists in dataset' % (n_unique_artists))\n",
    "\n",
    "for artist_songs in grouped_artist_song_rdd.take(5):\n",
    "    print('\\n%s has %d songs:' % (artist_songs[0], len(artist_songs[1])))\n",
    "    songs = ''\n",
    "    for song in artist_songs[1]:\n",
    "        print('- %s' % (song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 artists have no songs\n"
     ]
    }
   ],
   "source": [
    "# check if any artist has no songs -- shouldn't be possible\n",
    "print('%d artists have no songs' % (grouped_artist_song_rdd.filter(lambda x: len(x[1]) < 1).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
