{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Spark setup\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import hdf5_getters\n",
    "from pyspark.sql.types import FloatType, IntegerType, StructField, StructType\n",
    "\n",
    "from tools import setup_spark_config\n",
    "\n",
    "sc, spark = setup_spark_config(\"Exploring Million Song Dataset\")\n",
    "\n",
    "# add local files to spark so that workers can use them as well\n",
    "homedir = str(os.getcwd())+'/'\n",
    "if 'ubuntu' in homedir:\n",
    "    sc.addPyFile('/home/ubuntu/hdf5_getters.py')\n",
    "    sc.addPyFile('/home/ubuntu/tools.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all subdirs\n",
    "def get_subdirs(basedir, homedir):\n",
    "    subdirs = []\n",
    "    for subdir in next(os.walk(homedir+basedir))[1]:\n",
    "        subdirs.append(os.path.join(basedir, subdir))\n",
    "    return subdirs\n",
    "\n",
    "homedir = str(os.getcwd())+'/'\n",
    "basedir = 'MillionSongSubset'\n",
    "subdirs_rdd = sc.parallelize(get_subdirs(basedir, homedir))\n",
    "subsubdirs_rdd = subdirs_rdd.map(lambda subdir: get_subdirs(subdir, homedir)).flatMap(lambda x: x)\n",
    "subsubsubdirs_rdd = subsubdirs_rdd.map(lambda subsubdir: get_subdirs(subsubdir, homedir)).flatMap(lambda x: x)\n",
    "subsubsubdirs_rdd = subsubsubdirs_rdd.map(lambda subsubsubdir: homedir+subsubsubdir).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894 dirs in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/R',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/U',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/I',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/N',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/G']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('%d dirs in dataset' % (subsubsubdirs_rdd.count()))\n",
    "subsubsubdirs_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate & get all files (songs)\n",
    "def count_and_get_files(basedir, ext='.h5'):\n",
    "    # modified version of: https://labrosa.ee.columbia.edu/millionsong/pages/iterate-over-all-songs\n",
    "    cnt = 0\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "        cnt += len(files)\n",
    "    return cnt, all_files\n",
    "\n",
    "file_names_rdd = subsubsubdirs_rdd \\\n",
    "                    .map(lambda subsubsubdir: count_and_get_files(subsubsubdir)[1]) \\\n",
    "                    .flatMap(lambda x: x) \\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 files in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/R/TRARRZU128F4253CA2.h5',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/R/TRARRJL128F92DED0E.h5',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/R/TRARRUZ128F9307C57.h5',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/R/TRARRWA128F42A0195.h5',\n",
       " '/Users/kasper/Development/school/LDSA-project/MillionSongSubset/A/R/R/TRARRPG12903CD1DE9.h5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('%d files in dataset' % (file_names_rdd.count()))\n",
    "file_names_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample artist: Raphaël,       \n",
      "song: Je Sais Que La Terre Est Plate,       \n",
      "artist familiarity: 0.56,       \n",
      "artist hotness: 0.39,       \n",
      "song hotness: 0.55,       \n",
      "key: 0,       \n",
      "tempo: 124.06       \n",
      "year: 2008\n"
     ]
    }
   ],
   "source": [
    "# Inspect some sample data\n",
    "h5 = hdf5_getters.open_h5_file_read(file_names_rdd.take(1)[0])\n",
    "\n",
    "# in byte format --> decode to string\n",
    "print('Sample artist: %s, \\\n",
    "      \\nsong: %s, \\\n",
    "      \\nartist familiarity: %0.2f, \\\n",
    "      \\nartist hotness: %0.2f, \\\n",
    "      \\nsong hotness: %0.2f, \\\n",
    "      \\nkey: %d, \\\n",
    "      \\ntempo: %0.2f \\\n",
    "      \\nyear: %d' % \\\n",
    "      (hdf5_getters.get_artist_name(h5).decode('UTF-8'), \\\n",
    "       hdf5_getters.get_title(h5).decode('UTF-8'), \\\n",
    "       float(hdf5_getters.get_artist_familiarity(h5)), \\\n",
    "       float(hdf5_getters.get_artist_hotttnesss(h5)), \\\n",
    "       float(hdf5_getters.get_song_hotttnesss(h5)), \\\n",
    "       int(hdf5_getters.get_key(h5)), \\\n",
    "       float(hdf5_getters.get_tempo(h5)), \\\n",
    "       int(hdf5_getters.get_year(h5))))\n",
    "\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get artist name for each song\n",
    "def get_artist_name(filename):\n",
    "    file = hdf5_getters.open_h5_file_read(filename)\n",
    "    artist_name = hdf5_getters.get_artist_name(file).decode('UTF-8')\n",
    "    file.close()\n",
    "    return artist_name\n",
    "\n",
    "artist_names_rdd = file_names_rdd.map(get_artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raphaël',\n",
       " 'Julie Zenatti',\n",
       " 'The Baltimore Consort',\n",
       " 'I Hate Sally',\n",
       " 'Orlando Pops Orchestra']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_names_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all artists and songs in format: (artist, song)\n",
    "def get_artist_and_song(filename):\n",
    "    file = hdf5_getters.open_h5_file_read(filename)\n",
    "    artist = hdf5_getters.get_artist_name(file).decode('UTF-8')\n",
    "    song = hdf5_getters.get_title(file).decode('UTF-8')\n",
    "    file.close()\n",
    "    return artist, song\n",
    "\n",
    "artist_song_rdd = file_names_rdd.map(lambda x: get_artist_and_song(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group songs by their artist in format: (artist, [song1, song2, song3...])\n",
    "# very slow operation --> if printing songs is uninteresting, use reduceByKey instead\n",
    "grouped_artist_song_rdd = artist_song_rdd.groupByKey().mapValues(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4412 unique artists in dataset\n",
      "\n",
      "The Baltimore Consort has 4 songs:\n",
      "- Howells Delight\n",
      "- The Beautiful Shepherdess of Arcadia\n",
      "- You Lasses and Lads\n",
      "- Howell\u0019s Delight\n",
      "\n",
      "Atreyu has 7 songs:\n",
      "- You Eclipsed By Me (Album Version)\n",
      "- Gallows (Album Version)\n",
      "- Nevada's Grace (Album Version)\n",
      "- Ex's And Oh's (Instrumental Version)\n",
      "- The Remembrance Ballad (Album Version)\n",
      "- Blood Children (an Introduction) (Album Version)\n",
      "- Shameful (LP Version)\n",
      "\n",
      "Mistress has 1 songs:\n",
      "- Shovel\n",
      "\n",
      "Linkin Park has 3 songs:\n",
      "- Crawling (Album Version)\n",
      "- Given Up (Album Version)\n",
      "- Pushing Me Away (Album Version)\n",
      "\n",
      "Jimmy Riley has 9 songs:\n",
      "- Amaze\n",
      "- Amaze\n",
      "- Conversation\n",
      "- Simple Communication\n",
      "- The Love We Had Version\n",
      "- Show Of Love\n",
      "- Life\n",
      "- Prophecy\n",
      "- Watch This Sounds\n"
     ]
    }
   ],
   "source": [
    "n_unique_artists = grouped_artist_song_rdd.count()\n",
    "print('%d unique artists in dataset' % (n_unique_artists))\n",
    "\n",
    "for artist_songs in grouped_artist_song_rdd.take(5):\n",
    "    print('\\n%s has %d songs:' % (artist_songs[0], len(artist_songs[1])))\n",
    "    songs = ''\n",
    "    for song in artist_songs[1]:\n",
    "        print('- %s' % (song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 artists have no songs\n"
     ]
    }
   ],
   "source": [
    "# check if any artist has no songs -- shouldn't be possible\n",
    "print('%d artists have no songs' % (grouped_artist_song_rdd.filter(lambda x: len(x[1]) < 1).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get song data to use for analysis\n",
    "def get_song_data(filename):\n",
    "    # round floats to 2 decimals\n",
    "    file = hdf5_getters.open_h5_file_read(filename)\n",
    "    loudness = float(hdf5_getters.get_loudness(file))\n",
    "    song_hotness = float(hdf5_getters.get_song_hotttnesss(file))\n",
    "    year = int(hdf5_getters.get_year(file))    \n",
    "    artist_familiarity = float(hdf5_getters.get_artist_familiarity(file))\n",
    "    artist_hotness = float(hdf5_getters.get_artist_hotttnesss(file))\n",
    "    key = int(hdf5_getters.get_key(file))\n",
    "    tempo = float(hdf5_getters.get_tempo(file))\n",
    "    file.close()\n",
    "    return loudness, song_hotness, year, artist_familiarity, artist_hotness, key, tempo\n",
    "\n",
    "songs_rdd = file_names_rdd.map(get_song_data).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-9.636,\n",
       "  0.5479529419800353,\n",
       "  2008,\n",
       "  0.5574602197393447,\n",
       "  0.3861516314132549,\n",
       "  0,\n",
       "  124.059),\n",
       " (-11.061,\n",
       "  0.47563846801023907,\n",
       "  2004,\n",
       "  0.6269577230052118,\n",
       "  0.43485958934341257,\n",
       "  1,\n",
       "  80.084),\n",
       " (-24.14, nan, 0, 0.42572365804650586, 0.0, 3, 54.874),\n",
       " (-5.795, nan, 2007, 0.6114954183523941, 0.3345197638116389, 7, 77.15),\n",
       " (-16.477, nan, 0, 0.3672550107574772, 0.3116155449734521, 10, 120.382)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move song data from RDD to DF & table view for optimization & Spark-SQL queries\n",
    "fields = [StructField(\"loudness\", FloatType()), \\\n",
    "          StructField(\"song_hotness\", FloatType()), \\\n",
    "          StructField(\"year\", IntegerType()), \\\n",
    "          StructField(\"artist_familiarity\", FloatType()), \\\n",
    "          StructField(\"artist_hotness\", FloatType()), \\\n",
    "          StructField(\"key\", IntegerType()), \\\n",
    "          StructField(\"tempo\", FloatType())]\n",
    "\n",
    "schema = StructType(fields)\n",
    "\n",
    "songs_df = spark.createDataFrame(songs_rdd, schema)\n",
    "songs_df.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "|  -9.636|  0.54795295|2008|        0.55746025|    0.38615164|  0|124.059|\n",
      "| -11.061|  0.47563848|2004|         0.6269577|     0.4348596|  1| 80.084|\n",
      "|  -24.14|         NaN|   0|        0.42572367|           0.0|  3| 54.874|\n",
      "|  -5.795|         NaN|2007|        0.61149544|    0.33451977|  7|  77.15|\n",
      "| -16.477|         NaN|   0|          0.367255|    0.31161556| 10|120.382|\n",
      "| -12.474|  0.44545454|   0|         0.6013057|    0.36367568|  9| 99.024|\n",
      "|  -4.393|  0.32773668|   0|        0.70901054|    0.55356616|  9|175.673|\n",
      "|   -5.05|         NaN|   0|         0.5480224|     0.4401347|  1| 87.999|\n",
      "|  -4.264|   0.7883882|1982|        0.73703754|     0.5392454| 10| 92.897|\n",
      "| -13.885|         NaN|1998|        0.43591547|    0.35814852|  4| 86.981|\n",
      "|  -4.707|    0.681092|2004|         0.8218443|     0.5924395|  0|157.715|\n",
      "|  -4.523|  0.40148672|2005|        0.49579692|    0.38949883|  0|146.331|\n",
      "|  -4.076|   0.6878737|2004|        0.73343325|     0.4555588|  0| 84.992|\n",
      "| -19.293|   0.2669552|   0|        0.57082534|    0.40358824|  2|  79.96|\n",
      "|  -3.312|  0.35528553|2001|        0.48433375|     0.3359355|  1| 99.959|\n",
      "|  -6.619|  0.54352427|   0|        0.61869216|    0.42272136|  1|135.503|\n",
      "| -25.651|  0.21508032|1982|         0.5772761|    0.37693998|  1|104.989|\n",
      "|  -6.052|  0.87222904|2000|         0.8873861|      0.791143|  4|105.095|\n",
      "|  -7.164|         NaN|   0|        0.45344493|     0.3116175|  0| 89.572|\n",
      "|  -5.704|         NaN|   0|        0.38031706|    0.30091843|  4|107.986|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 songs in total\n"
     ]
    }
   ],
   "source": [
    "n_songs = file_names_rdd.count() # each file corresponds to one song\n",
    "print(\"There are %d songs in total\" % (n_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out songs with NaN values and no year\n",
    "filtered_songs_df = spark.sql(\"SELECT * FROM songs WHERE \\\n",
    "                                  isNaN(loudness) = false AND \\\n",
    "                                  isNaN(song_hotness) = false AND \\\n",
    "                                  isNaN(year) = false AND \\\n",
    "                                  year > 0 AND \\\n",
    "                                  isNaN(artist_familiarity) = false AND \\\n",
    "                                  isNaN(artist_hotness) = false AND \\\n",
    "                                  isNaN(key) = false AND \\\n",
    "                                  isNaN(tempo) = false\")\n",
    "filtered_songs_df.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "|  -9.636|  0.54795295|2008|        0.55746025|    0.38615164|  0|124.059|\n",
      "| -11.061|  0.47563848|2004|         0.6269577|     0.4348596|  1| 80.084|\n",
      "|  -4.264|   0.7883882|1982|        0.73703754|     0.5392454| 10| 92.897|\n",
      "|  -4.707|    0.681092|2004|         0.8218443|     0.5924395|  0|157.715|\n",
      "|  -4.523|  0.40148672|2005|        0.49579692|    0.38949883|  0|146.331|\n",
      "|  -4.076|   0.6878737|2004|        0.73343325|     0.4555588|  0| 84.992|\n",
      "|  -3.312|  0.35528553|2001|        0.48433375|     0.3359355|  1| 99.959|\n",
      "| -25.651|  0.21508032|1982|         0.5772761|    0.37693998|  1|104.989|\n",
      "|  -6.052|  0.87222904|2000|         0.8873861|      0.791143|  4|105.095|\n",
      "| -15.433|   0.5968407|1981|         0.6559214|     0.5783016|  5|100.042|\n",
      "|  -4.325|   0.6248335|2007|        0.55454856|     0.4115458|  3| 92.971|\n",
      "|  -5.193|  0.42744657|2008|          0.612543|    0.45966047| 11|117.936|\n",
      "|  -6.712|         0.0|2004|         0.6117883|    0.33672684|  7|104.465|\n",
      "|   -4.13|   0.4871122|2007|         0.9089843|     0.5625067|  4| 91.026|\n",
      "|  -7.687|  0.28848165|1978|        0.51462424|    0.36951157|  4|134.985|\n",
      "|  -7.687|   0.5675917|1995|         0.6639529|    0.39207578| 11|  88.12|\n",
      "|  -21.82|  0.50403434|2000|        0.67497027|    0.42495307|  5|131.281|\n",
      "|  -5.548|      0.5764|2005|        0.63204175|     0.3879116|  9|136.945|\n",
      "|  -7.057|   0.4764352|2007|        0.89993495|    0.68365806|  1| 188.91|\n",
      "| -13.845|   0.2998775|1986|        0.61760867|    0.40596735|  7|156.285|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_songs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3064 songs left after removing songs with NaN values, corresponding to 30.64% of the total amount of songs\n"
     ]
    }
   ],
   "source": [
    "n_songs_left = filtered_songs_df.count()\n",
    "n_songs_left_frac = n_songs_left / n_songs * 100\n",
    "print(\"There are %d songs left after removing songs with NaN values, corresponding to %0.2f%% of the total amount of songs\" \\\n",
    "       % (n_songs_left, n_songs_left_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs to parquet (better than CSV)\n",
    "dst_dir = homedir+'parsed-'+basedir\n",
    "if os.path.isdir(dst_dir):\n",
    "    shutil.rmtree(dst_dir)\n",
    "filtered_songs_df.write.parquet(dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs to CSV (for comparison purposes)\n",
    "save_as_csv = False\n",
    "if save_as_csv:\n",
    "    dst_dir = homedir+'parsed-'+basedir+'-csv'\n",
    "    if os.path.isdir(dst_dir):\n",
    "        shutil.rmtree(dst_dir)\n",
    "    filtered_songs_df.write.csv(dst_dir, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
