{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Spark setup\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import hdf5_getters\n",
    "from pyspark.sql.types import FloatType, IntegerType, StructField, StructType, StringType\n",
    "from pyspark.ml.feature import QuantileDiscretizer, VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import broadcast, udf\n",
    "import numpy as np\n",
    "\n",
    "from tools import setup_spark_config, read_parquet_files\n",
    "\n",
    "sc, spark = setup_spark_config(\"Full Analysis Of Million Song Dataset \")\n",
    "\n",
    "# add local files to spark so that workers can use them as well\n",
    "homedir = str(os.getcwd())+'/'\n",
    "if 'ubuntu' in homedir:\n",
    "    sc.addPyFile('/home/ubuntu/hdf5_getters.py')\n",
    "    sc.addPyFile('/home/ubuntu/tools.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all subdirs\n",
    "def get_subdirs(basedir, homedir):\n",
    "    subdirs = []\n",
    "    for subdir in next(os.walk(homedir+basedir))[1]:\n",
    "        subdirs.append(os.path.join(basedir, subdir))\n",
    "    return subdirs\n",
    "\n",
    "homedir = str(os.getcwd())+'/'\n",
    "basedir = 'datasets'\n",
    "subdirs_rdd = sc.parallelize(get_subdirs(basedir, homedir))\n",
    "subsubdirs_rdd = subdirs_rdd.map(lambda subdir: get_subdirs(subdir, homedir)).flatMap(lambda x: x)\n",
    "subsubsubdirs_rdd = subsubdirs_rdd.map(lambda subsubdir: get_subdirs(subsubdir, homedir)).flatMap(lambda x: x)\n",
    "subsubsubdirs_rdd = subsubsubdirs_rdd.map(lambda subsubsubdir: homedir+subsubsubdir).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028 dirs in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/datasets/C/U/U',\n",
       " '/home/ubuntu/datasets/C/U/X',\n",
       " '/home/ubuntu/datasets/C/U/V',\n",
       " '/home/ubuntu/datasets/C/U/M',\n",
       " '/home/ubuntu/datasets/C/U/J']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('%d dirs in dataset' % (subsubsubdirs_rdd.count()))\n",
    "subsubsubdirs_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate & get all files (songs)\n",
    "def count_and_get_files(basedir, ext='.h5'):\n",
    "    # modified version of: https://labrosa.ee.columbia.edu/millionsong/pages/iterate-over-all-songs\n",
    "    cnt = 0\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "        cnt += len(files)\n",
    "    return cnt, all_files\n",
    "\n",
    "file_names_rdd = subsubsubdirs_rdd \\\n",
    "                    .map(lambda subsubsubdir: count_and_get_files(subsubsubdir)[1]) \\\n",
    "                    .flatMap(lambda x: x) \\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115976 files in dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/datasets/C/U/U/TRCUUHJ128F932110C.h5',\n",
       " '/home/ubuntu/datasets/C/U/U/TRCUUMC12903CFF894.h5',\n",
       " '/home/ubuntu/datasets/C/U/U/TRCUUEI128F9329C49.h5',\n",
       " '/home/ubuntu/datasets/C/U/U/TRCUUXR12903CDCD7E.h5',\n",
       " '/home/ubuntu/datasets/C/U/U/TRCUUSB128F92F4413.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('%d files in dataset' % (file_names_rdd.count()))\n",
    "file_names_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_names = file_names_rdd.take(15040) # 3.5gb\n",
    "#file_names = file_names_rdd.take(30080) # 7gb\n",
    "file_names = file_names_rdd.take(45120) # 10.5gb\n",
    "#file_names = file_names_rdd.take(60160) # 14gb\n",
    "#file_names = file_names_rdd.take(75200) # 17.5gb\n",
    "#file_names = file_names_rdd.take(90240) # 21gb\n",
    "\n",
    "file_names_rdd = sc.parallelize(file_names).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample artist: Cesare Cremonini,       \n",
      "song: Dev'essere cosi (unplugged),       \n",
      "artist familiarity: 0.60,       \n",
      "artist hotness: 0.43,       \n",
      "song hotness: 0.35,       \n",
      "key: 4,       \n",
      "tempo: 187.40       \n",
      "year: 2008\n"
     ]
    }
   ],
   "source": [
    "# Inspect some sample data\n",
    "h5 = hdf5_getters.open_h5_file_read(file_names_rdd.take(1)[0])\n",
    "\n",
    "# in byte format --> decode to string\n",
    "print('Sample artist: %s, \\\n",
    "      \\nsong: %s, \\\n",
    "      \\nartist familiarity: %0.2f, \\\n",
    "      \\nartist hotness: %0.2f, \\\n",
    "      \\nsong hotness: %0.2f, \\\n",
    "      \\nkey: %d, \\\n",
    "      \\ntempo: %0.2f \\\n",
    "      \\nyear: %d' % \\\n",
    "      (hdf5_getters.get_artist_name(h5).decode('UTF-8'), \\\n",
    "       hdf5_getters.get_title(h5).decode('UTF-8'), \\\n",
    "       float(hdf5_getters.get_artist_familiarity(h5)), \\\n",
    "       float(hdf5_getters.get_artist_hotttnesss(h5)), \\\n",
    "       float(hdf5_getters.get_song_hotttnesss(h5)), \\\n",
    "       int(hdf5_getters.get_key(h5)), \\\n",
    "       float(hdf5_getters.get_tempo(h5)), \\\n",
    "       int(hdf5_getters.get_year(h5))))\n",
    "\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get artist name for each song\n",
    "def get_artist_name(filename):\n",
    "    file = hdf5_getters.open_h5_file_read(filename)\n",
    "    artist_name = hdf5_getters.get_artist_name(file).decode('UTF-8')\n",
    "    file.close()\n",
    "    return artist_name\n",
    "\n",
    "artist_names_rdd = file_names_rdd.map(get_artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cesare Cremonini',\n",
       " 'Adam Richmond',\n",
       " 'The Mother Truckers',\n",
       " 'utopia:banished',\n",
       " 'California Oranges']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_names_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all artists and songs in format: (artist, song)\n",
    "def get_artist_and_song(filename):\n",
    "    file = hdf5_getters.open_h5_file_read(filename)\n",
    "    artist = hdf5_getters.get_artist_name(file).decode('UTF-8')\n",
    "    song = hdf5_getters.get_title(file).decode('UTF-8')\n",
    "    file.close()\n",
    "    return artist, song\n",
    "\n",
    "artist_song_rdd = file_names_rdd.map(lambda x: get_artist_and_song(x)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group songs by their artist in format: (artist, [song1, song2, song3...])\n",
    "# very slow operation --> if printing songs is uninteresting, use reduceByKey instead\n",
    "grouped_artist_song_rdd = artist_song_rdd.groupByKey().mapValues(list).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23560 unique artists in dataset\n",
      "\n",
      "Gloria Estefan has 3 songs:\n",
      "- Me Odio\n",
      "- No Me Vuelvo A Enamorar\n",
      "- Cuts Both Ways\n",
      "\n",
      "Lulu has 5 songs:\n",
      "- Every Woman Knows (Think Twice Remix)\n",
      "- Saved (2007 Remastered LP Version)\n",
      "- Sois libre et ris\n",
      "- I'll Come Running Over\n",
      "- Take Good Care Of Yourself (2007 Remastered LP Version)\n",
      "\n",
      "POCAHONTAS has 1 songs:\n",
      "- Hijo De La Luna\n",
      "\n",
      "Los Lobos has 3 songs:\n",
      "- I Got To Let You Know [Live at The Paradiso_ Amsterdam 1987]\n",
      "- Estoy Sentado Aquí\n",
      "- Come On Let's Go\n",
      "\n",
      "Cesare Basile has 1 songs:\n",
      "- Waltz # 4\n"
     ]
    }
   ],
   "source": [
    "n_unique_artists = grouped_artist_song_rdd.count()\n",
    "print('%d unique artists in dataset' % (n_unique_artists))\n",
    "\n",
    "for artist_songs in grouped_artist_song_rdd.take(5):\n",
    "    print('\\n%s has %d songs:' % (artist_songs[0], len(artist_songs[1])))\n",
    "    songs = ''\n",
    "    for song in artist_songs[1]:\n",
    "        print('- %s' % (song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 artists have no songs\n"
     ]
    }
   ],
   "source": [
    "# check if any artist has no songs -- shouldn't be possible\n",
    "print('%d artists have no songs' % (grouped_artist_song_rdd.filter(lambda x: len(x[1]) < 1).count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get song data to use for analysis\n",
    "def get_song_data(filename):\n",
    "    # round floats to 2 decimals\n",
    "    file = hdf5_getters.open_h5_file_read(filename)\n",
    "    loudness = float(hdf5_getters.get_loudness(file))\n",
    "    song_hotness = float(hdf5_getters.get_song_hotttnesss(file))\n",
    "    year = int(hdf5_getters.get_year(file))    \n",
    "    artist_familiarity = float(hdf5_getters.get_artist_familiarity(file))\n",
    "    artist_hotness = float(hdf5_getters.get_artist_hotttnesss(file))\n",
    "    key = int(hdf5_getters.get_key(file))\n",
    "    tempo = float(hdf5_getters.get_tempo(file))\n",
    "    file.close()\n",
    "    return loudness, song_hotness, year, artist_familiarity, artist_hotness, key, tempo\n",
    "\n",
    "songs_rdd = file_names_rdd.map(get_song_data).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-16.346,\n",
       "  0.34911996465177997,\n",
       "  2008,\n",
       "  0.5997560759410356,\n",
       "  0.42955964045297707,\n",
       "  4,\n",
       "  187.402),\n",
       " (-15.124, nan, 0, 0.16951676160053092, 0.27417477953702857, 2, 110.2),\n",
       " (-8.663, nan, 0, 0.5820459775659689, 0.3619682702757134, 7, 120.1),\n",
       " (-8.206, nan, 0, 0.522553237646043, 0.33196871960348096, 10, 169.054),\n",
       " (-5.571,\n",
       "  0.21204540548371908,\n",
       "  0,\n",
       "  0.4242028280284693,\n",
       "  0.2554103094339133,\n",
       "  11,\n",
       "  154.868)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move song data from RDD to DF & table view for optimization & Spark-SQL queries\n",
    "fields = [StructField(\"loudness\", FloatType()), \\\n",
    "          StructField(\"song_hotness\", FloatType()), \\\n",
    "          StructField(\"year\", IntegerType()), \\\n",
    "          StructField(\"artist_familiarity\", FloatType()), \\\n",
    "          StructField(\"artist_hotness\", FloatType()), \\\n",
    "          StructField(\"key\", IntegerType()), \\\n",
    "          StructField(\"tempo\", FloatType())]\n",
    "\n",
    "schema = StructType(fields)\n",
    "\n",
    "songs_df = spark.createDataFrame(songs_rdd, schema)\n",
    "songs_df.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "| -16.346|  0.34911996|2008|        0.59975606|    0.42955965|  4|187.402|\n",
      "| -15.124|         NaN|   0|        0.16951676|    0.27417478|  2|  110.2|\n",
      "|  -8.663|         NaN|   0|          0.582046|    0.36196828|  7|  120.1|\n",
      "|  -8.206|         NaN|   0|        0.52255327|    0.33196872| 10|169.054|\n",
      "|  -5.571|   0.2120454|   0|        0.42420283|     0.2554103| 11|154.868|\n",
      "|  -9.749|  0.52683705|   0|        0.70708585|    0.45426837|  4|110.516|\n",
      "|  -3.975|  0.53237844|2007|         0.8513696|     0.5836399|  7|150.114|\n",
      "| -11.614|         NaN|   0|         0.6089661|     0.4037475|  7|179.416|\n",
      "|  -9.094|         0.0|1993|         0.4612176|    0.32213077| 11|127.772|\n",
      "|  -7.559|         NaN|   0|         0.5565503|     0.3414383|  2|148.831|\n",
      "| -13.309|         0.0|   0|        0.59031373|    0.38142812| 11|111.609|\n",
      "|  -7.934|         0.0|   0|        0.31982753|     0.4004695|  9|180.122|\n",
      "| -13.972|         NaN|2000|        0.41733822|    0.34229887|  6| 96.055|\n",
      "|  -7.975|   0.4432913|   0|        0.52072006|     0.3120389|  4|127.002|\n",
      "|  -6.869|  0.26586103|   0|        0.60560876|     0.3545631|  9| 98.986|\n",
      "|  -6.436|         NaN|   0|        0.50790787|    0.41152766|  2|111.465|\n",
      "| -25.359|         NaN|   0|         0.4065294|    0.31786433|  5|110.794|\n",
      "|  -8.248|   0.8478813|   0|         0.6949144|    0.47063228|  0|136.761|\n",
      "|  -7.867|         NaN|   0|        0.55474627|    0.42092356|  7|127.974|\n",
      "|   -7.81|         NaN|2004|        0.48466283|    0.40452975|  7|171.809|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45120 songs in total\n"
     ]
    }
   ],
   "source": [
    "n_songs = file_names_rdd.count() # each file corresponds to one song\n",
    "print(\"There are %d songs in total\" % (n_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out songs with NaN values and no year\n",
    "filtered_songs_df = spark.sql(\"SELECT * FROM songs WHERE \\\n",
    "                                  isNaN(loudness) = false AND \\\n",
    "                                  isNaN(song_hotness) = false AND \\\n",
    "                                  isNaN(year) = false AND \\\n",
    "                                  year > 0 AND \\\n",
    "                                  isNaN(artist_familiarity) = false AND \\\n",
    "                                  isNaN(artist_hotness) = false AND \\\n",
    "                                  isNaN(key) = false AND \\\n",
    "                                  isNaN(tempo) = false\")\n",
    "filtered_songs_df.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "| -16.346|  0.34911996|2008|        0.59975606|    0.42955965|  4|187.402|\n",
      "|  -3.975|  0.53237844|2007|         0.8513696|     0.5836399|  7|150.114|\n",
      "|  -9.094|         0.0|1993|         0.4612176|    0.32213077| 11|127.772|\n",
      "|  -7.548|   0.2998775|2005|         0.5636851|    0.32525325|  5|  156.5|\n",
      "|  -7.688|  0.42870227|2009|         0.4956395|    0.37228364|  4|119.288|\n",
      "| -15.216|   0.4518259|1996|        0.48260397|    0.29409504|  8| 97.388|\n",
      "| -18.329|    0.541552|1976|        0.67577136|     0.4354689|  7|151.361|\n",
      "|  -8.325|   0.4381202|2003|        0.54568464|      0.396207|  6|133.635|\n",
      "| -17.636|   0.7462104|2006|           0.70012|     0.5343837|  7|120.632|\n",
      "|  -9.352|   0.2291441|2001|         0.5058246|    0.34626162|  1| 96.005|\n",
      "|  -8.017|         0.0|2009|        0.55974865|     0.4296056|  4|130.026|\n",
      "|  -9.919|  0.44711617|2005|        0.54921687|    0.36313447|  9| 77.089|\n",
      "|  -8.341|   0.5460937|2008|         0.7722927|     0.5421752|  7| 97.059|\n",
      "| -11.011|  0.34092274|2007|        0.47683606|    0.33054537|  4| 108.93|\n",
      "|  -5.066|  0.34580225|2006|        0.55847603|    0.30834994|  7|125.045|\n",
      "|  -4.667|   0.7027931|2004|          0.715781|      0.568197|  9| 169.79|\n",
      "|  -9.958|         0.0|1998|        0.49597424|    0.38237616| 11|125.566|\n",
      "|  -5.682|         0.0|1999|         0.5768462|     0.3639709|  0|146.194|\n",
      "|  -4.706|   0.5929321|1985|          0.749797|     0.5515525|  4|102.263|\n",
      "| -13.322|  0.34092274|2000|         0.5885974|    0.37413442|  4| 58.204|\n",
      "+--------+------------+----+------------------+--------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_songs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15320 songs left after removing songs with NaN values, corresponding to 33.95% of the total amount of songs\n"
     ]
    }
   ],
   "source": [
    "n_songs_left = filtered_songs_df.count()\n",
    "n_songs_left_frac = n_songs_left / n_songs * 100\n",
    "print(\"There are %d songs left after removing songs with NaN values, corresponding to %0.2f%% of the total amount of songs\" \\\n",
    "       % (n_songs_left, n_songs_left_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs to parquet (better than CSV)\n",
    "dst_dir = homedir+'parsed-'+basedir\n",
    "if os.path.isdir(dst_dir):\n",
    "    shutil.rmtree(dst_dir)\n",
    "filtered_songs_df.write.parquet(dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# write songs to CSV (for comparison purposes)\\ndst_dir = homedir+'parsed-'+basedir+'-csv'\\nif os.path.isdir(dst_dir):\\n    shutil.rmtree(dst_dir)\\nfiltered_songs_df.write.csv(dst_dir, header=True)\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# write songs to CSV (for comparison purposes)\n",
    "dst_dir = homedir+'parsed-'+basedir+'-csv'\n",
    "if os.path.isdir(dst_dir):\n",
    "    shutil.rmtree(dst_dir)\n",
    "filtered_songs_df.write.csv(dst_dir, header=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read songs data from parquet files\n",
    "basedir = homedir+'parsed-'+basedir\n",
    "songs_df = read_parquet_files(basedir, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group songs by year\n",
    "grouped_year_songs_df = spark.sql(\"SELECT AVG(loudness), \\\n",
    "                              AVG(song_hotness), AVG(artist_familiarity), \\\n",
    "                              AVG(key), AVG(tempo), \\\n",
    "                              AVG(artist_hotness), year FROM songs \\\n",
    "                              GROUP BY year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are songs from 61 different years in the dataset\n"
     ]
    }
   ],
   "source": [
    "n_years = grouped_year_songs_df.count()\n",
    "print(\"There are songs from %d different years in the dataset\" % (n_years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------------+------------------+------------------+-------------------+----+\n",
      "|      avg(loudness)|  avg(song_hotness)|avg(artist_familiarity)|          avg(key)|        avg(tempo)|avg(artist_hotness)|year|\n",
      "+-------------------+-------------------+-----------------------+------------------+------------------+-------------------+----+\n",
      "| -3.993000030517578|  0.644711971282959|     0.6272614598274231|               2.0| 143.0050048828125| 0.5325385928153992|2011|\n",
      "| -8.028590893590605| 0.5416193984739193|     0.6237667761501167|5.0811688311688314| 124.9831883690574| 0.4522572713238852|2010|\n",
      "| -7.964498000171132|0.49272277063416864|     0.6169314381263095| 5.351297405189621|122.80484237214048| 0.4377286074582688|2009|\n",
      "| -8.195168193681694|0.46935270025209275|     0.6181123493906703| 5.221206581352834|124.39913437614929|0.43039013528464265|2008|\n",
      "| -8.015104006290436|0.44904645688533784|     0.6212394068658352|            5.2808|124.10426083984375| 0.4294569036245346|2007|\n",
      "|  -8.32664741241253|0.42570819130395127|     0.6031978519713752| 5.309045226130653|124.79097733106246|0.41346590103615866|2006|\n",
      "| -8.373027126098659| 0.4472229502906115|     0.6130767232190071| 5.611548556430447|123.01254599530344| 0.4217538671960772|2005|\n",
      "|  -8.93240919479957|0.41079546929870403|     0.6032896256949912| 5.545940170940171|  124.276525623778|0.41191505305528736|2004|\n",
      "| -8.894215134473948| 0.4216209648248668|     0.6073727014367111| 5.221153846153846|125.62809501244472|0.42059321011989736|2003|\n",
      "| -9.012563444996147| 0.4198677654961329|     0.6022811518317008| 5.304044630404463|124.03220653666945|0.41405338720214585|2002|\n",
      "| -8.940650162126857|0.40978079554203994|     0.5977509217798362| 5.332361516034985|125.45347382514886| 0.4141504941806849|2001|\n",
      "| -9.423194429216286|0.40132696290190023|     0.5987511784607906| 5.409722222222222|122.99752423167229|0.40716526604309267|2000|\n",
      "|  -9.51576449063377|0.40336234235893126|     0.6031061872920912| 5.193840579710145|123.58747825069705|0.41736440841054573|1999|\n",
      "| -9.833600011467933|   0.38981870074446|     0.6002129486917208| 5.489583333333333|126.09404612382254|0.41084690308198335|1998|\n",
      "|-10.033106931864817|0.39974956171284276|     0.6129488231477334|5.2071269487750556|126.67242080756445| 0.4166565264320055|1997|\n",
      "|-10.489182237240907|0.38694186790955726|     0.5898728200214373| 5.592326139088729|123.00320853546656|0.40779943896426285|1996|\n",
      "|-10.784463781453969| 0.3931912651969664|     0.5883729740897389| 5.388739946380697|126.15724425021828|0.41335832537339134|1995|\n",
      "| -11.00681710524545| 0.4058925430771172|     0.5999511638573841| 4.929203539823009|124.12380523456585|0.42059722859247595|1994|\n",
      "|-11.931585442803122| 0.4129133212566376|     0.6028075544942509| 5.458181818181818|126.60186183929443| 0.4212235805121335|1993|\n",
      "|-11.505438467172477|0.38980439202143596|     0.5883796296583919| 5.515384615384615|125.80956897735595| 0.4072201408732396|1992|\n",
      "+-------------------+-------------------+-----------------------+------------------+------------------+-------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_year_songs_df.orderBy(\"year\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.09% correlation between loudness and year\n",
      "7.95% correlation between song_hotness and year\n",
      "5.47% correlation between artist_familiarity and year\n",
      "1.51% correlation between key and year\n",
      "-1.09% correlation between tempo and year\n",
      "3.48% correlation between artist_hotness and year\n"
     ]
    }
   ],
   "source": [
    "# see linear correlation between years and the other features\n",
    "loudness_correlation = 100*float(songs_df.stat.corr(\"loudness\", \"year\"))\n",
    "song_hotness_correlation = 100*float(songs_df.stat.corr(\"song_hotness\", \"year\"))\n",
    "artist_familiarity_correlation = 100*float(songs_df.stat.corr(\"artist_familiarity\", \"year\"))\n",
    "key_correlation = 100*float(songs_df.stat.corr(\"key\", \"year\"))\n",
    "tempo_correlation = 100*float(songs_df.stat.corr(\"tempo\", \"year\"))\n",
    "artist_hotness_correlation = 100*float(songs_df.stat.corr(\"artist_hotness\", \"year\"))\n",
    "\n",
    "print(\"%0.2f%% correlation between loudness and year\" % (loudness_correlation))\n",
    "print(\"%0.2f%% correlation between song_hotness and year\" % (song_hotness_correlation))\n",
    "print(\"%0.2f%% correlation between artist_familiarity and year\" % (artist_familiarity_correlation))\n",
    "print(\"%0.2f%% correlation between key and year\" % (key_correlation))\n",
    "print(\"%0.2f%% correlation between tempo and year\" % (tempo_correlation))\n",
    "print(\"%0.2f%% correlation between artist_hotness and year\" % (artist_hotness_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.57% correlation between avg(loudness) and year\n",
      "26.40% correlation between avg(song_hotness) and year\n",
      "50.81% correlation between avg(artist_familiarity) and year\n",
      "-7.27% correlation between avg(key) and year\n",
      "50.23% correlation between avg(tempo) and year\n",
      "50.76% correlation between avg(artist_hotness) and year\n"
     ]
    }
   ],
   "source": [
    "# see linear correlation between years and the average of other features\n",
    "loudness_correlation = 100*float(grouped_year_songs_df.stat.corr(\"avg(loudness)\", \"year\"))\n",
    "song_hotness_correlation = 100*float(grouped_year_songs_df.stat.corr(\"avg(song_hotness)\", \"year\"))\n",
    "artist_familiarity_correlation = 100*float(grouped_year_songs_df.stat.corr(\"avg(artist_familiarity)\", \"year\"))\n",
    "key_correlation = 100*float(grouped_year_songs_df.stat.corr(\"avg(key)\", \"year\"))\n",
    "tempo_correlation = 100*float(grouped_year_songs_df.stat.corr(\"avg(tempo)\", \"year\"))\n",
    "artist_hotness_correlation = 100*float(grouped_year_songs_df.stat.corr(\"avg(artist_hotness)\", \"year\"))\n",
    "\n",
    "print(\"%0.2f%% correlation between avg(loudness) and year\" % (loudness_correlation))\n",
    "print(\"%0.2f%% correlation between avg(song_hotness) and year\" % (song_hotness_correlation))\n",
    "print(\"%0.2f%% correlation between avg(artist_familiarity) and year\" % (artist_familiarity_correlation))\n",
    "print(\"%0.2f%% correlation between avg(key) and year\" % (key_correlation))\n",
    "print(\"%0.2f%% correlation between avg(tempo) and year\" % (tempo_correlation))\n",
    "print(\"%0.2f%% correlation between avg(artist_hotness) and year\" % (artist_hotness_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize hotness to 10 different values\n",
    "discretizer = QuantileDiscretizer(numBuckets=10, inputCol=\"song_hotness\", outputCol=\"discrete_song_hotness\")\n",
    "discretized_df = discretizer.fit(songs_df).transform(songs_df)\n",
    "discretized_df.createOrReplaceTempView(\"discrete_hotness_songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+---------------------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|discrete_song_hotness|\n",
      "+--------+------------+----+------------------+--------------+---+-------+---------------------+\n",
      "| -16.346|  0.34911996|2008|        0.59975606|    0.42955965|  4|187.402|                  3.0|\n",
      "|  -3.975|  0.53237844|2007|         0.8513696|     0.5836399|  7|150.114|                  6.0|\n",
      "|  -9.094|         0.0|1993|         0.4612176|    0.32213077| 11|127.772|                  1.0|\n",
      "|  -7.548|   0.2998775|2005|         0.5636851|    0.32525325|  5|  156.5|                  2.0|\n",
      "|  -7.688|  0.42870227|2009|         0.4956395|    0.37228364|  4|119.288|                  4.0|\n",
      "| -15.216|   0.4518259|1996|        0.48260397|    0.29409504|  8| 97.388|                  4.0|\n",
      "| -18.329|    0.541552|1976|        0.67577136|     0.4354689|  7|151.361|                  6.0|\n",
      "|  -8.325|   0.4381202|2003|        0.54568464|      0.396207|  6|133.635|                  4.0|\n",
      "| -17.636|   0.7462104|2006|           0.70012|     0.5343837|  7|120.632|                  9.0|\n",
      "|  -9.352|   0.2291441|2001|         0.5058246|    0.34626162|  1| 96.005|                  1.0|\n",
      "|  -8.017|         0.0|2009|        0.55974865|     0.4296056|  4|130.026|                  1.0|\n",
      "|  -9.919|  0.44711617|2005|        0.54921687|    0.36313447|  9| 77.089|                  4.0|\n",
      "|  -8.341|   0.5460937|2008|         0.7722927|     0.5421752|  7| 97.059|                  6.0|\n",
      "| -11.011|  0.34092274|2007|        0.47683606|    0.33054537|  4| 108.93|                  3.0|\n",
      "|  -5.066|  0.34580225|2006|        0.55847603|    0.30834994|  7|125.045|                  3.0|\n",
      "|  -4.667|   0.7027931|2004|          0.715781|      0.568197|  9| 169.79|                  9.0|\n",
      "|  -9.958|         0.0|1998|        0.49597424|    0.38237616| 11|125.566|                  1.0|\n",
      "|  -5.682|         0.0|1999|         0.5768462|     0.3639709|  0|146.194|                  1.0|\n",
      "|  -4.706|   0.5929321|1985|          0.749797|     0.5515525|  4|102.263|                  7.0|\n",
      "| -13.322|  0.34092274|2000|         0.5885974|    0.37413442|  4| 58.204|                  3.0|\n",
      "+--------+------------+----+------------------+--------------+---+-------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "discretized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group songs by hotness\n",
    "grouped_hotness_songs_df = spark.sql(\"SELECT AVG(loudness), \\\n",
    "                              AVG(artist_familiarity), \\\n",
    "                              AVG(key), AVG(tempo), \\\n",
    "                              AVG(artist_hotness), discrete_song_hotness FROM discrete_hotness_songs \\\n",
    "                              GROUP BY discrete_song_hotness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+-----------------+------------------+-------------------+---------------------+\n",
      "|      avg(loudness)|avg(artist_familiarity)|         avg(key)|        avg(tempo)|avg(artist_hotness)|discrete_song_hotness|\n",
      "+-------------------+-----------------------+-----------------+------------------+-------------------+---------------------+\n",
      "| -8.264136008105673|     0.7182547533578691|5.366622864651774|124.61489686702774| 0.5150832961192269|                  9.0|\n",
      "|  -8.61522301401565|     0.6790808589663055|5.180349062702004|125.24948229478419|0.47486551014469297|                  8.0|\n",
      "| -8.868828756591073|     0.6474130619012939|5.363398692810457|126.70131234063042|0.45046668712025373|                  7.0|\n",
      "| -8.949385912450227|     0.6242417906820191|5.431551499348109|125.74190221585071|0.43281927654298685|                  6.0|\n",
      "| -9.615878017195206|     0.6009626929612985|5.395303326810176|124.90745083397692| 0.4169134982780779|                  5.0|\n",
      "| -9.486051608774881|     0.5869789239430373|5.280862181580666| 124.6286747046034|0.40659750011098067|                  4.0|\n",
      "| -9.798881879551336|     0.5711446928151418|         5.189375|124.00330941915512| 0.3969919107016176|                  3.0|\n",
      "|-10.210238450937277|     0.5569525983830825|5.323509711989283|124.41479382575636|0.38121651274720375|                  2.0|\n",
      "|-10.389335317383505|     0.5347478400064454| 5.36072607260726|122.99817559774166| 0.3620729892994139|                  1.0|\n",
      "+-------------------+-----------------------+-----------------+------------------+-------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_hotness_songs_df.orderBy(\"discrete_song_hotness\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.39% correlation between loudness and discrete_song_hotness\n",
      "45.49% correlation between artist_hotness and discrete_song_hotness\n",
      "48.42% correlation between artist_familiarity and discrete_song_hotness\n",
      "-0.04% correlation between key and discrete_song_hotness\n",
      "2.29% correlation between tempo and discrete_song_hotness\n",
      "45.49% correlation between year and discrete_song_hotness\n"
     ]
    }
   ],
   "source": [
    "# see linear correlation between discrete_hotness and the other features\n",
    "loudness_correlation = 100*float(discretized_df.stat.corr(\"loudness\", \"discrete_song_hotness\"))\n",
    "artist_hotness_correlation = 100*float(discretized_df.stat.corr(\"artist_hotness\", \"discrete_song_hotness\"))\n",
    "artist_familiarity_correlation = 100*float(discretized_df.stat.corr(\"artist_familiarity\", \"discrete_song_hotness\"))\n",
    "key_correlation = 100*float(discretized_df.stat.corr(\"key\", \"discrete_song_hotness\"))\n",
    "tempo_correlation = 100*float(discretized_df.stat.corr(\"tempo\", \"discrete_song_hotness\"))\n",
    "year_correlation = 100*float(discretized_df.stat.corr(\"year\", \"discrete_song_hotness\"))\n",
    "\n",
    "print(\"%0.2f%% correlation between loudness and discrete_song_hotness\" % (loudness_correlation))\n",
    "print(\"%0.2f%% correlation between artist_hotness and discrete_song_hotness\" % (artist_hotness_correlation))\n",
    "print(\"%0.2f%% correlation between artist_familiarity and discrete_song_hotness\" % (artist_familiarity_correlation))\n",
    "print(\"%0.2f%% correlation between key and discrete_song_hotness\" % (key_correlation))\n",
    "print(\"%0.2f%% correlation between tempo and discrete_song_hotness\" % (tempo_correlation))\n",
    "print(\"%0.2f%% correlation between year and discrete_song_hotness\" % (artist_hotness_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.54% correlation between avg(loudness) and discrete_song_hotness\n",
      "97.77% correlation between avg(artist_hotness) and discrete_song_hotness\n",
      "98.50% correlation between avg(artist_familiarity) and discrete_song_hotness\n",
      "4.82% correlation between avg(key) and discrete_song_hotness\n",
      "67.34% correlation between avg(tempo) and discrete_song_hotness\n"
     ]
    }
   ],
   "source": [
    "# see linear correlation between discrete_hotness and the average of the other features\n",
    "loudness_correlation = 100*float(grouped_hotness_songs_df.stat.corr(\"avg(loudness)\", \"discrete_song_hotness\"))\n",
    "song_hotness_correlation = 100*float(grouped_hotness_songs_df.stat.corr(\"avg(artist_hotness)\", \"discrete_song_hotness\"))\n",
    "artist_familiarity_correlation = 100*float(grouped_hotness_songs_df.stat.corr(\"avg(artist_familiarity)\", \"discrete_song_hotness\"))\n",
    "key_correlation = 100*float(grouped_hotness_songs_df.stat.corr(\"avg(key)\", \"discrete_song_hotness\"))\n",
    "tempo_correlation = 100*float(grouped_hotness_songs_df.stat.corr(\"avg(tempo)\", \"discrete_song_hotness\"))\n",
    "\n",
    "print(\"%0.2f%% correlation between avg(loudness) and discrete_song_hotness\" % (loudness_correlation))\n",
    "print(\"%0.2f%% correlation between avg(artist_hotness) and discrete_song_hotness\" % (song_hotness_correlation))\n",
    "print(\"%0.2f%% correlation between avg(artist_familiarity) and discrete_song_hotness\" % (artist_familiarity_correlation))\n",
    "print(\"%0.2f%% correlation between avg(key) and discrete_song_hotness\" % (key_correlation))\n",
    "print(\"%0.2f%% correlation between avg(tempo) and discrete_song_hotness\" % (tempo_correlation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to vector to use for clustering\n",
    "input_cols = [\"loudness\", \\\n",
    "              \"song_hotness\", \\\n",
    "              \"artist_familiarity\", \\\n",
    "              \"artist_hotness\", \\\n",
    "              \"key\", \\\n",
    "              \"tempo\"]\n",
    "vecAssembler = VectorAssembler(inputCols=input_cols, \\\n",
    "                               outputCol=\"features\")\n",
    "vec_df = vecAssembler.transform(songs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+--------------------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|            features|\n",
      "+--------+------------+----+------------------+--------------+---+-------+--------------------+\n",
      "| -16.346|  0.34911996|2008|        0.59975606|    0.42955965|  4|187.402|[-16.346000671386...|\n",
      "|  -3.975|  0.53237844|2007|         0.8513696|     0.5836399|  7|150.114|[-3.9749999046325...|\n",
      "|  -9.094|         0.0|1993|         0.4612176|    0.32213077| 11|127.772|[-9.0939998626708...|\n",
      "|  -7.548|   0.2998775|2005|         0.5636851|    0.32525325|  5|  156.5|[-7.5479998588562...|\n",
      "|  -7.688|  0.42870227|2009|         0.4956395|    0.37228364|  4|119.288|[-7.6880002021789...|\n",
      "| -15.216|   0.4518259|1996|        0.48260397|    0.29409504|  8| 97.388|[-15.215999603271...|\n",
      "| -18.329|    0.541552|1976|        0.67577136|     0.4354689|  7|151.361|[-18.329000473022...|\n",
      "|  -8.325|   0.4381202|2003|        0.54568464|      0.396207|  6|133.635|[-8.3249998092651...|\n",
      "| -17.636|   0.7462104|2006|           0.70012|     0.5343837|  7|120.632|[-17.635999679565...|\n",
      "|  -9.352|   0.2291441|2001|         0.5058246|    0.34626162|  1| 96.005|[-9.3520002365112...|\n",
      "|  -8.017|         0.0|2009|        0.55974865|     0.4296056|  4|130.026|[-8.0170001983642...|\n",
      "|  -9.919|  0.44711617|2005|        0.54921687|    0.36313447|  9| 77.089|[-9.9189996719360...|\n",
      "|  -8.341|   0.5460937|2008|         0.7722927|     0.5421752|  7| 97.059|[-8.3409996032714...|\n",
      "| -11.011|  0.34092274|2007|        0.47683606|    0.33054537|  4| 108.93|[-11.010999679565...|\n",
      "|  -5.066|  0.34580225|2006|        0.55847603|    0.30834994|  7|125.045|[-5.0659999847412...|\n",
      "|  -4.667|   0.7027931|2004|          0.715781|      0.568197|  9| 169.79|[-4.6669998168945...|\n",
      "|  -9.958|         0.0|1998|        0.49597424|    0.38237616| 11|125.566|[-9.9580001831054...|\n",
      "|  -5.682|         0.0|1999|         0.5768462|     0.3639709|  0|146.194|[-5.6820001602172...|\n",
      "|  -4.706|   0.5929321|1985|          0.749797|     0.5515525|  4|102.263|[-4.7059998512268...|\n",
      "| -13.322|  0.34092274|2000|         0.5885974|    0.37413442|  4| 58.204|[-13.321999549865...|\n",
      "+--------+------------+----+------------------+--------------+---+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a KMeans model to the vector transform of the grouped (by year) data\n",
    "kmeans = KMeans(k=len(input_cols), seed=1)\n",
    "model = kmeans.fit(vec_df.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the vector transform of the grouped (by year) data\n",
    "transformed_df = model.transform(vec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----+------------------+--------------+---+-------+--------------------+----------+\n",
      "|loudness|song_hotness|year|artist_familiarity|artist_hotness|key|  tempo|            features|prediction|\n",
      "+--------+------------+----+------------------+--------------+---+-------+--------------------+----------+\n",
      "| -16.346|  0.34911996|2008|        0.59975606|    0.42955965|  4|187.402|[-16.346000671386...|         5|\n",
      "|  -3.975|  0.53237844|2007|         0.8513696|     0.5836399|  7|150.114|[-3.9749999046325...|         0|\n",
      "|  -9.094|         0.0|1993|         0.4612176|    0.32213077| 11|127.772|[-9.0939998626708...|         3|\n",
      "|  -7.548|   0.2998775|2005|         0.5636851|    0.32525325|  5|  156.5|[-7.5479998588562...|         2|\n",
      "|  -7.688|  0.42870227|2009|         0.4956395|    0.37228364|  4|119.288|[-7.6880002021789...|         3|\n",
      "| -15.216|   0.4518259|1996|        0.48260397|    0.29409504|  8| 97.388|[-15.215999603271...|         4|\n",
      "| -18.329|    0.541552|1976|        0.67577136|     0.4354689|  7|151.361|[-18.329000473022...|         0|\n",
      "|  -8.325|   0.4381202|2003|        0.54568464|      0.396207|  6|133.635|[-8.3249998092651...|         0|\n",
      "| -17.636|   0.7462104|2006|           0.70012|     0.5343837|  7|120.632|[-17.635999679565...|         3|\n",
      "|  -9.352|   0.2291441|2001|         0.5058246|    0.34626162|  1| 96.005|[-9.3520002365112...|         4|\n",
      "|  -8.017|         0.0|2009|        0.55974865|     0.4296056|  4|130.026|[-8.0170001983642...|         0|\n",
      "|  -9.919|  0.44711617|2005|        0.54921687|    0.36313447|  9| 77.089|[-9.9189996719360...|         4|\n",
      "|  -8.341|   0.5460937|2008|         0.7722927|     0.5421752|  7| 97.059|[-8.3409996032714...|         4|\n",
      "| -11.011|  0.34092274|2007|        0.47683606|    0.33054537|  4| 108.93|[-11.010999679565...|         3|\n",
      "|  -5.066|  0.34580225|2006|        0.55847603|    0.30834994|  7|125.045|[-5.0659999847412...|         3|\n",
      "|  -4.667|   0.7027931|2004|          0.715781|      0.568197|  9| 169.79|[-4.6669998168945...|         2|\n",
      "|  -9.958|         0.0|1998|        0.49597424|    0.38237616| 11|125.566|[-9.9580001831054...|         3|\n",
      "|  -5.682|         0.0|1999|         0.5768462|     0.3639709|  0|146.194|[-5.6820001602172...|         0|\n",
      "|  -4.706|   0.5929321|1985|          0.749797|     0.5515525|  4|102.263|[-4.7059998512268...|         4|\n",
      "| -13.322|  0.34092274|2000|         0.5885974|    0.37413442|  4| 58.204|[-13.321999549865...|         1|\n",
      "+--------+------------+----+------------------+--------------+---+-------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for each centroid\n",
    "centroids = model.clusterCenters()\n",
    "centroids = np.array(centroids).T.tolist()\n",
    "centroids.append([i for i in range(len(input_cols))])\n",
    "\n",
    "R = Row(\"loudness\", \\\n",
    "        \"song_hotness\", \\\n",
    "        \"artist_familiarity\", \\\n",
    "        \"artist_hotness\", \\\n",
    "        \"key\", \\\n",
    "        \"tempo\", \\\n",
    "        \"centroid\")\n",
    "centroids_df = sc.parallelize([R(*r) for r in zip(*centroids)]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+-------------------+------------------+------------------+--------+\n",
      "|           loudness|      song_hotness|artist_familiarity|     artist_hotness|               key|             tempo|centroid|\n",
      "+-------------------+------------------+------------------+-------------------+------------------+------------------+--------+\n",
      "| -8.858958260339122|0.4325800949433544|0.6063084503764415| 0.4208683091039593|5.3645645645645645|139.63880275233728|       0|\n",
      "|-13.855989993140755| 0.398096589350581| 0.594022916191641|  0.416415683831903| 5.160200250312891|  60.7642752023155|       1|\n",
      "| -8.680848375059838| 0.437697964220546|0.6100420256270919| 0.4220462501049042| 5.261860465116279|166.68070898011675|       2|\n",
      "| -9.499035311602103|0.4234504753298597|0.6035877241560436| 0.4188378432803185| 5.392938209331652|118.15619771988665|       3|\n",
      "|  -9.63685176697683|0.4296833192086197|0.6069181274227154|0.42129169335256766| 5.267635843660629| 92.84466947659182|       4|\n",
      "|  -8.56193635379049|0.4309294509616765|0.6049583581699566|  0.414485367980193|5.4363636363636365|203.77231249375777|       5|\n",
      "+-------------------+------------------+------------------+-------------------+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "centroids_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fictional genre to each centroid\n",
    "genres = [\"hot&loud\", \"plain\", \"mellow&soft\", \"mainstream\", \"hip&hop\", \"R&B\"]\n",
    "\n",
    "def add_genre(centroid):\n",
    "    print(centroid)\n",
    "    return genres[int(centroid)]\n",
    "\n",
    "udf_add_genre = udf(add_genre, StringType())\n",
    "genres_df = centroids_df.withColumn(\"genre\", udf_add_genre(\"centroid\")).select(\"centroid\", \"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add centroid genre to songs\n",
    "song_genres_df = transformed_df.join(broadcast(genres_df), transformed_df.prediction == genres_df.centroid) \\\n",
    "    .select(\"loudness\", \\\n",
    "            \"song_hotness\", \\\n",
    "            \"artist_familiarity\", \\\n",
    "            \"artist_hotness\", \\\n",
    "            \"key\", \\\n",
    "            \"tempo\", \\\n",
    "            \"genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------------+--------------+---+-------+-----------+\n",
      "|loudness|song_hotness|artist_familiarity|artist_hotness|key|  tempo|      genre|\n",
      "+--------+------------+------------------+--------------+---+-------+-----------+\n",
      "| -16.346|  0.34911996|        0.59975606|    0.42955965|  4|187.402|        R&B|\n",
      "|  -3.975|  0.53237844|         0.8513696|     0.5836399|  7|150.114|   hot&loud|\n",
      "|  -9.094|         0.0|         0.4612176|    0.32213077| 11|127.772| mainstream|\n",
      "|  -7.548|   0.2998775|         0.5636851|    0.32525325|  5|  156.5|mellow&soft|\n",
      "|  -7.688|  0.42870227|         0.4956395|    0.37228364|  4|119.288| mainstream|\n",
      "| -15.216|   0.4518259|        0.48260397|    0.29409504|  8| 97.388|    hip&hop|\n",
      "| -18.329|    0.541552|        0.67577136|     0.4354689|  7|151.361|   hot&loud|\n",
      "|  -8.325|   0.4381202|        0.54568464|      0.396207|  6|133.635|   hot&loud|\n",
      "| -17.636|   0.7462104|           0.70012|     0.5343837|  7|120.632| mainstream|\n",
      "|  -9.352|   0.2291441|         0.5058246|    0.34626162|  1| 96.005|    hip&hop|\n",
      "|  -8.017|         0.0|        0.55974865|     0.4296056|  4|130.026|   hot&loud|\n",
      "|  -9.919|  0.44711617|        0.54921687|    0.36313447|  9| 77.089|    hip&hop|\n",
      "|  -8.341|   0.5460937|         0.7722927|     0.5421752|  7| 97.059|    hip&hop|\n",
      "| -11.011|  0.34092274|        0.47683606|    0.33054537|  4| 108.93| mainstream|\n",
      "|  -5.066|  0.34580225|        0.55847603|    0.30834994|  7|125.045| mainstream|\n",
      "|  -4.667|   0.7027931|          0.715781|      0.568197|  9| 169.79|mellow&soft|\n",
      "|  -9.958|         0.0|        0.49597424|    0.38237616| 11|125.566| mainstream|\n",
      "|  -5.682|         0.0|         0.5768462|     0.3639709|  0|146.194|   hot&loud|\n",
      "|  -4.706|   0.5929321|          0.749797|     0.5515525|  4|102.263|    hip&hop|\n",
      "| -13.322|  0.34092274|         0.5885974|    0.37413442|  4| 58.204|      plain|\n",
      "+--------+------------+------------------+--------------+---+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "song_genres_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_genres_df.createOrReplaceTempView(\"songs_with_genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3965 mainstream songs in the dataset\n",
      "There are 3330 hot&loud songs in the dataset\n",
      "There are 2150 mellow&soft songs in the dataset\n",
      "There are 799 plain songs in the dataset\n"
     ]
    }
   ],
   "source": [
    "n_mainstream_songs = spark.sql(\"SELECT COUNT(*) FROM songs_with_genres WHERE genre = \\\"mainstream\\\"\").collect()[0][0]\n",
    "n_hotnloud_songs = spark.sql(\"SELECT COUNT(*) FROM songs_with_genres WHERE genre = \\\"hot&loud\\\"\").collect()[0][0]\n",
    "n_mellownsoft_songs = spark.sql(\"SELECT COUNT(*) FROM songs_with_genres WHERE genre = \\\"mellow&soft\\\"\").collect()[0][0]\n",
    "n_plain_songs = spark.sql(\"SELECT COUNT(*) FROM songs_with_genres WHERE genre = \\\"plain\\\"\").collect()[0][0]\n",
    "\n",
    "print(\"There are %d mainstream songs in the dataset\" % (n_mainstream_songs))\n",
    "print(\"There are %d hot&loud songs in the dataset\" % (n_hotnloud_songs))\n",
    "print(\"There are %d mellow&soft songs in the dataset\" % (n_mellownsoft_songs))\n",
    "print(\"There are %d plain songs in the dataset\" % (n_plain_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
